{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import spacy\n",
    "import re\n",
    "from pprint import pprint\n",
    "import nltk\n",
    "#nltk.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from collections import Counter\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('path/to/topic_modelling_sklearn_results.pkl')\n",
    "df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-Processing\n",
    "# Remove links\n",
    "def remove_links(tweet):\n",
    "    tweet_no_link = re.sub(r\"http\\S+\", \"\", tweet)\n",
    "    return tweet_no_link\n",
    "df['tweet_text_p'] = np.vectorize(remove_links)(df['Tweet'])\n",
    "def remove_links(tweet):\n",
    "    tweet_no_link = re.sub(r\"twitter.com\\S+\", \"\", tweet)\n",
    "    return tweet_no_link\n",
    "df['tweet_text_p'] = np.vectorize(remove_links)(df['tweet_text_p'])\n",
    "\n",
    "# Remove Twitter Handlers (@Users)\n",
    "def remove_users(tweet, pattern1, pattern2):\n",
    "    r = re.findall(pattern1, tweet)\n",
    "    for i in r:\n",
    "        tweet = re.sub(i, '', tweet)\n",
    "    \n",
    "    r = re.findall(pattern2, tweet)\n",
    "    for i in r:\n",
    "        tweet = re.sub(i, '', tweet)\n",
    "    return tweet\n",
    "df['tweet_text_p'] = np.vectorize(remove_users)(df['tweet_text_p'], \"@ [\\w]*\", \"@[\\w]*\")\n",
    "\n",
    "# Remove Hashtag Symbol\n",
    "# I decided to keep hashtags because they add value to the sentiment.\n",
    "def remove_hashtags(tweet, pattern1):\n",
    "    r = re.findall(pattern1, tweet)\n",
    "    for i in r:\n",
    "        tweet = re.sub(i, '', tweet)\n",
    "    return tweet\n",
    "df['tweet_text_p'] = np.vectorize(remove_hashtags)(df['tweet_text_p'], \"#\")\n",
    "\n",
    "# Do not Remove Punctuation\n",
    "\n",
    "# Removing Punctuation has no significant impact in most cases \n",
    "# In some cases reduces the neutrality because of words in parentheses\n",
    "# df['pre_processed_1'] = df['pre_processed'].str.replace(\"[^a-zA-Z#]\", \" \")\n",
    "\n",
    "# Remove Duplicates\n",
    "df.drop_duplicates(subset=['tweet_text_p'], keep='first', inplace=True)\n",
    "df = df[~df.tweet_text_p.str.contains(\"Retweeted\")]\n",
    "df.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an object of Vader Sentiment Analyzer\n",
    "vader_analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "negative = []\n",
    "neutral = []\n",
    "positive = []\n",
    "compound = []\n",
    "\n",
    "def sentiment_scores(df, negative, neutral, positive, compound):\n",
    "    for i in df['tweet_text_p']:\n",
    "        sentiment_dict = vader_analyzer.polarity_scores(i)\n",
    "        negative.append(sentiment_dict['neg'])\n",
    "        neutral.append(sentiment_dict['neu'])\n",
    "        positive.append(sentiment_dict['pos'])\n",
    "        compound.append(sentiment_dict['compound'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function calling \n",
    "sentiment_scores(df, negative, neutral, positive, compound)\n",
    "\n",
    "# Prepare columns to add the scores later\n",
    "df[\"negative\"] = negative\n",
    "df[\"neutral\"] = neutral\n",
    "df[\"positive\"] = positive\n",
    "df[\"compound\"] = compound\n",
    "\n",
    "# Fill the overall sentiment with encoding:\n",
    "# (-1)Negative, (0)Neutral, (1)Positive\n",
    "sentiment = []\n",
    "for i in df['compound']:\n",
    "    if i >= 0.05 : \n",
    "        sentiment.append(1)\n",
    "  \n",
    "    elif i <= - 0.05 : \n",
    "        sentiment.append(-1) \n",
    "        \n",
    "    else : \n",
    "        sentiment.append(0)\n",
    "df['sentiment'] = sentiment\n",
    "neg_tweets = df.sentiment.value_counts()[-1]\n",
    "neu_tweets = df.sentiment.value_counts()[0]\n",
    "pos_tweets = df.sentiment.value_counts()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data0 = [df[df.dominant_topic == 0].sentiment.value_counts()[-1], df[df.dominant_topic == 0].sentiment.value_counts()[0], df[df.dominant_topic == 0].sentiment.value_counts()[1]]\n",
    "data1 = [df[df.dominant_topic == 1].sentiment.value_counts()[-1], df[df.dominant_topic == 1].sentiment.value_counts()[0], df[df.dominant_topic == 1].sentiment.value_counts()[1]]\n",
    "data2 = [df[df.dominant_topic == 2].sentiment.value_counts()[-1], df[df.dominant_topic == 2].sentiment.value_counts()[0], df[df.dominant_topic == 2].sentiment.value_counts()[1]]\n",
    "data3 = [df[df.dominant_topic == 3].sentiment.value_counts()[-1], df[df.dominant_topic == 3].sentiment.value_counts()[0], df[df.dominant_topic == 3].sentiment.value_counts()[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of tweets by sentiment per Topic\n",
    "# Pie Chart\n",
    "\n",
    "# Draw Plot\n",
    "fig, ax = plt.subplots(figsize=(15, 6), subplot_kw=dict(aspect=\"equal\"), dpi= 80)\n",
    "\n",
    "\n",
    "categories = ['Negative', 'Neutral', 'Positive']\n",
    "explode = [0.05,0.05,0.05]\n",
    "\n",
    "def func(pct, allvals):\n",
    "    absolute = int(pct/100.*np.sum(allvals))\n",
    "    return \"{:.1f}% ({:d} )\".format(pct, absolute)\n",
    "\n",
    "wedges, texts, autotexts = ax.pie(data0, \n",
    "                                autopct=lambda pct: func(pct, data0),\n",
    "                                textprops=dict(color=\"w\"), \n",
    "                                colors=['#e55039', '#3c6382', '#78e08f'],\n",
    "                                startangle=140,\n",
    "                                explode=explode)\n",
    "\n",
    "# Decoration\n",
    "ax.legend(wedges, categories, title=\"Sentiment\", loc=\"center left\", bbox_to_anchor=(1, 0.2, 0.5, 1))\n",
    "plt.setp(autotexts, size=10, weight=700)\n",
    "ax.set_title(\"Number of Tweets by Sentiment\", fontsize=12, fontweight=\"bold\")\n",
    "plt.savefig('path/to/SentPlot0.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 6), subplot_kw=dict(aspect=\"equal\"), dpi= 80)\n",
    "\n",
    "\n",
    "wedges, texts, autotexts = ax.pie(data1, \n",
    "                                autopct=lambda pct: func(pct, data1),\n",
    "                                textprops=dict(color=\"w\"), \n",
    "                                colors=['#e55039', '#3c6382', '#78e08f'],\n",
    "                                startangle=140,\n",
    "                                explode=explode)\n",
    "\n",
    "# Decoration\n",
    "ax.legend(wedges, categories, title=\"Sentiment\", loc=\"center left\", bbox_to_anchor=(1, 0.2, 0.5, 1))\n",
    "plt.setp(autotexts, size=10, weight=700)\n",
    "ax.set_title(\"Number of Tweets by Sentiment\", fontsize=12, fontweight=\"bold\")\n",
    "plt.savefig('path/to/SentPlot1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 6), subplot_kw=dict(aspect=\"equal\"), dpi= 80)\n",
    "\n",
    "\n",
    "wedges, texts, autotexts = ax.pie(data2, \n",
    "                                autopct=lambda pct: func(pct, data2),\n",
    "                                textprops=dict(color=\"w\"), \n",
    "                                colors=['#e55039', '#3c6382', '#78e08f'],\n",
    "                                startangle=140,\n",
    "                                explode=explode)\n",
    "\n",
    "# Decoration\n",
    "ax.legend(wedges, categories, title=\"Sentiment\", loc=\"center left\", bbox_to_anchor=(1, 0.2, 0.5, 1))\n",
    "plt.setp(autotexts, size=10, weight=700)\n",
    "ax.set_title(\"Number of Tweets by Sentiment\", fontsize=12, fontweight=\"bold\")\n",
    "plt.savefig('path/to/SentPlot2.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 6), subplot_kw=dict(aspect=\"equal\"), dpi= 80)\n",
    "\n",
    "\n",
    "wedges, texts, autotexts = ax.pie(data3, \n",
    "                                autopct=lambda pct: func(pct, data3),\n",
    "                                textprops=dict(color=\"w\"), \n",
    "                                colors=['#e55039', '#3c6382', '#78e08f'],\n",
    "                                startangle=140,\n",
    "                                explode=explode)\n",
    "\n",
    "# Decoration\n",
    "ax.legend(wedges, categories, title=\"Sentiment\", loc=\"center left\", bbox_to_anchor=(1, 0.2, 0.5, 1))\n",
    "plt.setp(autotexts, size=10, weight=700)\n",
    "ax.set_title(\"Number of Tweets by Sentiment\", fontsize=12, fontweight=\"bold\")\n",
    "plt.savefig('path/to/SentPlot3.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a5e3ca5b78f5017bf8058e475be571c8c3aef9f26ab369f65f483a55f28d9ec3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
